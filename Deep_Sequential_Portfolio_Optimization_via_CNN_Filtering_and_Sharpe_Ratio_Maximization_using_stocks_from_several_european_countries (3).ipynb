{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Description**\n",
        "\n",
        "This notebook presents a sophisticated, two-stage Deep Learning (DL) framework for dynamic portfolio allocation, using real stock market data from a diverse universe of European companies.\n",
        "\n",
        "**Project Objective**\n",
        "\n",
        "The primary objective is to construct a long-only portfolio that maximizes the risk-adjusted return, measured by the Sharpe Ratio ($\\text{SR}$), over a multi-period backtesting window.\n",
        "\n",
        "I achieved this by moving beyond traditional Mean-Variance Optimization and leveraging the power of neural networks for end-to-end policy learning.\n",
        "\n",
        "**Methodology**:\n",
        "\n",
        "The Two-Stage Policy Network\n",
        "\n",
        "The system is built on a two-stage sequential decision process:\n",
        "\n",
        "**Stage 1: CNN-based Alpha Filtering**\n",
        "\n",
        "**Goal**: To filter the initial universe of stocks and select only those predicted to have an upward trend in the next period.\n",
        "\n",
        "This acts as a robust stock selection mechanism.\n",
        "\n",
        "**Architecture**: A Convolutional Neural Network (CNN) processes 2D \"image-like\" representations of time-series data.\n",
        "\n",
        "The inputs are multiple technical indicators (TIs) like RSI, MACD, and Stochastic Oscillators, calculated over a rolling window.\n",
        "\n",
        "**Output**: The CNN classifies stocks into one of three classes (Rise, Fall, Hold).\n",
        "\n",
        "Only stocks predicted to Rise are passed to Stage 2, significantly reducing the dimensionality of the subsequent optimization problem.\n",
        "\n",
        "**Stage 2: LSTM-based Sharpe Ratio Maximization**\n",
        "\n",
        "**Goal**: To determine the optimal allocation weights for the stocks selected in Stage 1.\n",
        "\n",
        "This acts as the capital allocation mechanism.\n",
        "\n",
        "**Architecture**: A Long Short-Term Memory (LSTM) network is used to capture sequential, multi-asset dependencies in the filtered stock data.\n",
        "\n",
        "**Key solution** :\n",
        "\n",
        "The model is trained using a custom loss function that directly minimizes the Negative Sharpe Ratio.\n",
        "\n",
        "By minimizing $-\\text{SR}$, the network is forced to learn portfolio weights that maximize the Sharpe Ratio, effectively making the network a policy network optimized for a financial metric rather than just prediction accuracy.\n",
        "\n",
        "**Robust Backtesting: Walk-Forward Optimization (WFO)**\n",
        "\n",
        "To ensure the simulation was realistic and free of look-ahead bias (a common pitfall in financial modeling), I employed a Walk-Forward Optimization (WFO) methodology:\n",
        "\n",
        "A fixed-size Training Window (e.g., 252 days) is defined.\n",
        "\n",
        "The models (CNN and LSTM) are trained only on the data within this window.\n",
        "\n",
        "A single-step prediction and allocation is made for the very next day.\n",
        "\n",
        "The window is advanced by one day, and the process repeats.\n",
        "\n",
        "**WARNING**:\n",
        "\n",
        "This notebook is not a financial advisor."
      ],
      "metadata": {
        "id": "dNh9P4HChfZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr3nhjUUSdog",
        "outputId": "63326a69-35bb-4bfd-a789-bcbcc470481c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=3c8173bb43c51a3522737efaad874b67a5039d2aab26ba1a8e57d37551639e78\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/a1/5f/c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import ta as ta_lib\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Dropout, TimeDistributed\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "QiuZohYdc9Mj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "TICKERS_BY_COUNTRY = {\n",
        "    'Germany': ['ALV.DE', 'DBK.DE', 'CBK.DE', 'HAG.DE', 'DB1.DE', 'FPE.DE', 'DHER.DE', 'MUV2.DE', 'VNA.DE', 'SDF.DE'],\n",
        "    'France': ['BNP.PA', 'ACA.PA', 'GLE.PA', 'CS.PA', 'OR.PA', 'ENGI.PA', 'SCR.PA', 'CA.PA', 'PUB.PA', 'SAN.PA'],\n",
        "    'UK': ['LLOY.L', 'BARC.L', 'HSBA.L', 'NWG.L', 'SSE.L', 'AV.L', 'PRU.L', 'LGEN.L', 'AHT.L', 'BP.L'],\n",
        "    'Spain': ['SAN.MC', 'BBVA.MC', 'CABK.MC', 'AMS.MC', 'MAP.MC', 'SAB.MC', 'ELE.MC', 'ENG.MC', 'IBE.MC', 'IAG.MC'],\n",
        "    'Italy': ['ISP.MI', 'UCG.MI', 'BAMI.MI', 'BMED.MI', 'FBK.MI', 'G.MI', 'AZM.MI', 'PST.MI', 'RACE.MI', 'IP.MI'],\n",
        "    'Netherlands': ['INGA.AS', 'ADYEN.AS', 'ABN.AS', 'WKL.AS', 'AD.AS', 'ASML.AS', 'HEIA.AS', 'TKWY.AS', 'KPN.AS'],\n",
        "    'Sweden': ['NDA-SE.ST', 'SEB-A.ST', 'SHB-A.ST', 'SWED-A.ST', 'GETI-B.ST', 'VOLV-B.ST', 'AZN.ST', 'TELIA.ST', 'ESSITY-B.ST', 'ERIC-B.ST'],\n",
        "    'Switzerland': ['UBSG.SW', 'VETN.SW', 'ZURN.SW', 'NESN.SW', 'SGSN.SW', 'CFR.SW', 'GIVN.SW', 'SREN.SW', 'NOVN.SW'],\n",
        "    'Belgium': ['KBC.BR', 'ABI.BR', 'UCB.BR', 'ACKB.BR', 'SOLB.BR', 'TUB.BR', 'ELI.BR', 'WDP.BR', 'COLR.BR']\n",
        "}\n",
        "\n",
        "TICKERS = [ticker for sublist in TICKERS_BY_COUNTRY.values() for ticker in sublist]\n",
        "START_DATE = '2021-01-01'\n",
        "END_DATE = '2025-09-30'\n",
        "WINDOW_SIZE = 30\n",
        "FLAT_THRESHOLD = 0.005\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_stock_data(tickers, start, end):\n",
        "\n",
        "    data = yf.download(tickers, start=start, end=end)\n",
        "    ti_data = {}\n",
        "\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        actual_tickers = data.columns.get_level_values(1).unique()\n",
        "    else:\n",
        "        actual_tickers = tickers\n",
        "\n",
        "    for ticker in actual_tickers:\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "            try:\n",
        "                df = data.xs(ticker, axis=1, level=1).copy()\n",
        "            except KeyError:\n",
        "                continue\n",
        "        else:\n",
        "            df = data.copy()\n",
        "            df.columns = [col.lower() for col in df.columns]\n",
        "\n",
        "        if df.empty or len(df) < (WINDOW_SIZE + 30):\n",
        "            continue\n",
        "\n",
        "        if isinstance(data.columns, pd.MultiIndex):\n",
        "             df.columns = [col.lower() for col in df.columns]\n",
        "\n",
        "        required_cols = ['high', 'low', 'close', 'volume']\n",
        "        if not all(col in df.columns for col in required_cols):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            df['RSI'] = ta_lib.momentum.rsi(df['close'], window=14)\n",
        "            macd_indicator = ta_lib.trend.MACD(close=df['close'])\n",
        "            df['MACD'] = macd_indicator.macd()\n",
        "            df['MACDh'] = macd_indicator.macd_diff()\n",
        "            df['MACDs'] = macd_indicator.macd_signal()\n",
        "            stoch = ta_lib.momentum.StochasticOscillator(df['high'], df['low'], df['close'])\n",
        "            df['stoch_k'] = stoch.stoch()\n",
        "            df['stoch_d'] = stoch.stoch_signal()\n",
        "            df['EMA_20'] = ta_lib.trend.ema_indicator(df['close'], window=20)\n",
        "        except Exception as e:\n",
        "            continue\n",
        "\n",
        "        keep_cols = ['close', 'RSI', 'MACD', 'MACDh', 'MACDs', 'stoch_k', 'stoch_d', 'EMA_20']\n",
        "        df = df[[col for col in keep_cols if col in df.columns]]\n",
        "\n",
        "        final_df = df.dropna()\n",
        "        if final_df.empty or len(final_df) < WINDOW_SIZE:\n",
        "            continue\n",
        "\n",
        "        ti_data[ticker] = final_df\n",
        "\n",
        "    return ti_data\n",
        "\n",
        "def create_classification_target(df, window=1, threshold=0.005):\n",
        "\n",
        "    df['future_return'] = df['close'].shift(-window) / df['close'] - 1\n",
        "    def classify(ret):\n",
        "        if ret > threshold:\n",
        "            return 2 # Rise\n",
        "        elif ret < -threshold:\n",
        "            return 0 # Fall\n",
        "        else:\n",
        "            return 1 # Flat\n",
        "    df['target'] = df['future_return'].apply(classify)\n",
        "    return df.dropna()\n",
        "\n",
        "\n",
        "def create_cnn_data(ti_datasets, stocks, window_size):\n",
        "\n",
        "    X_cnn, y_cnn = [], []\n",
        "    for ticker in stocks:\n",
        "        df = ti_datasets.get(ticker)\n",
        "        if df is None or df.empty or len(df) <= window_size:\n",
        "            continue\n",
        "\n",
        "        df = df.drop(columns=['close', 'future_return'], errors='ignore')\n",
        "\n",
        "        feature_cols = [col for col in df.columns if col != 'target']\n",
        "        if not feature_cols:\n",
        "            continue\n",
        "\n",
        "        features = df[feature_cols].values\n",
        "        targets = df['target'].values\n",
        "        n_features = features.shape[1]\n",
        "\n",
        "        for i in range(len(df) - window_size):\n",
        "            window = features[i:i + window_size]\n",
        "\n",
        "            X_cnn.append(window.reshape(window_size, n_features, 1))\n",
        "            y_cnn.append(targets[i + window_size - 1])\n",
        "\n",
        "    X_cnn = np.array(X_cnn)\n",
        "    y_cnn = to_categorical(np.array(y_cnn), num_classes=NUM_CLASSES)\n",
        "    return X_cnn, y_cnn\n",
        "\n",
        "def build_cnn_model(input_shape):\n",
        "\n",
        "    if not isinstance(input_shape, tuple) or len(input_shape) < 3:\n",
        "        return None\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (2, 2), activation='relu'),\n",
        "        MaxPooling2D((2, 1)),\n",
        "        Flatten(),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dense(NUM_CLASSES, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def cnn_filter_stocks(cnn_model, ti_datasets, stocks, window_size):\n",
        "    selected_stocks = []\n",
        "    if cnn_model is None:\n",
        "        print(\"CNN model is not available for filtering. Skipping stock selection.\")\n",
        "        return []\n",
        "\n",
        "    print(\"\\n--- Filtering stocks based on trained CNN prediction ('Rise' class=2) ---\")\n",
        "\n",
        "    for ticker in stocks:\n",
        "        df = ti_datasets.get(ticker)\n",
        "        if df is None or df.empty or len(df) < window_size:\n",
        "            continue\n",
        "\n",
        "        df_features = df.drop(columns=['close', 'future_return', 'target'], errors='ignore')\n",
        "        if df_features.empty:\n",
        "            continue\n",
        "\n",
        "        latest_features = df_features.tail(window_size).values\n",
        "        if latest_features.ndim < 2 or latest_features.shape[1] == 0:\n",
        "            continue\n",
        "\n",
        "        n_features = latest_features.shape[1]\n",
        "\n",
        "        X_latest = latest_features.reshape(1, window_size, n_features, 1)\n",
        "\n",
        "        try:\n",
        "            prediction = cnn_model.predict(X_latest, verbose=0)\n",
        "            predicted_class = np.argmax(prediction[0])\n",
        "        except Exception as e:\n",
        "            print(f\"Skipping {ticker}: CNN prediction failed. Error: {e}\")\n",
        "            predicted_class = 0\n",
        "\n",
        "        if predicted_class == 2:\n",
        "            selected_stocks.append(ticker)\n",
        "\n",
        "    return selected_stocks\n",
        "\n",
        "\n",
        "\n",
        "def negative_sharpe_ratio_loss(y_true, y_pred):\n",
        "\n",
        "    exp_pred = K.exp(y_pred)\n",
        "    weights = exp_pred / K.sum(exp_pred, axis=-1, keepdims=True)\n",
        "\n",
        "\n",
        "    portfolio_return = K.sum(weights * y_true, axis=-1)\n",
        "\n",
        "\n",
        "    mean_return = K.mean(portfolio_return)\n",
        "    std_return = K.std(portfolio_return)\n",
        "\n",
        "\n",
        "    sharpe_ratio = mean_return / (std_return + K.epsilon())\n",
        "\n",
        "\n",
        "    return -sharpe_ratio\n",
        "\n",
        "def create_lstm_data(ti_datasets, selected_stocks, window_size):\n",
        "\n",
        "    if not selected_stocks:\n",
        "        return np.array([]), pd.DataFrame(), None\n",
        "\n",
        "    aligned_dfs = []\n",
        "    for ticker in selected_stocks:\n",
        "\n",
        "        df = ti_datasets[ticker].drop(columns=['close', 'target'], errors='ignore')\n",
        "\n",
        "        df.columns = [f'{ticker}_{col}' for col in df.columns]\n",
        "        aligned_dfs.append(df)\n",
        "\n",
        "\n",
        "    combined_df = pd.concat(aligned_dfs, axis=1, join='inner').dropna()\n",
        "\n",
        "    feature_cols = [col for col in combined_df.columns if 'future_return' not in col]\n",
        "    return_cols = [f'{ticker}_future_return' for ticker in selected_stocks]\n",
        "\n",
        "    X_full = combined_df[feature_cols].values\n",
        "    y_full_returns_df = combined_df[return_cols]\n",
        "\n",
        "\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    X_scaled = scaler.fit_transform(X_full)\n",
        "\n",
        "    X_lstm, y_lstm_indices = [], []\n",
        "    for i in range(len(X_scaled) - window_size):\n",
        "\n",
        "        X_lstm.append(X_scaled[i:i + window_size])\n",
        "\n",
        "        y_lstm_indices.append(i + window_size)\n",
        "\n",
        "\n",
        "    y_lstm_returns = y_full_returns_df.iloc[y_lstm_indices]\n",
        "\n",
        "    return np.array(X_lstm), y_lstm_returns, scaler\n",
        "\n",
        "def build_lstm_model(input_shape, output_size):\n",
        "\n",
        "    model = Sequential([\n",
        "        LSTM(units=100, return_sequences=False, input_shape=input_shape),\n",
        "        Dense(50, activation='relu'),\n",
        "\n",
        "        Dense(output_size, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss=negative_sharpe_ratio_loss)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def calculate_metrics(returns):\n",
        "\n",
        "    annualization_factor = 252\n",
        "\n",
        "\n",
        "    cumulative_return = (1 + returns).prod() - 1\n",
        "\n",
        "\n",
        "    annualized_return = (cumulative_return + 1)**(annualization_factor / len(returns)) - 1\n",
        "\n",
        "\n",
        "    annualized_volatility = returns.std() * np.sqrt(annualization_factor)\n",
        "\n",
        "\n",
        "    sharpe_ratio = annualized_return / (annualized_volatility + 1e-8)\n",
        "\n",
        "    return annualized_return, annualized_volatility, sharpe_ratio, cumulative_return\n",
        "\n",
        "def walk_forward_backtest(X_all, y_all_returns, initial_train_idx, train_window, walk_step, n_epochs=2):\n",
        "\n",
        "    N_SAMPLES, N_TIMESTEPS, N_FEATURES_FLAT = X_all.shape\n",
        "    n_stocks_per_day = y_all_returns.shape[1]\n",
        "\n",
        "    lstm_model = build_lstm_model(X_all.shape[1:], n_stocks_per_day)\n",
        "\n",
        "\n",
        "    daily_returns = []\n",
        "    daily_dates = []\n",
        "\n",
        "\n",
        "    start_loop_index = initial_train_idx\n",
        "\n",
        "    print(\"\\nStarting Walk-Forward Loop...\")\n",
        "\n",
        "\n",
        "    for i in range(start_loop_index, len(X_all), walk_step):\n",
        "\n",
        "        train_end_idx = i\n",
        "        train_start_idx = train_end_idx - train_window\n",
        "\n",
        "        if train_start_idx < 0:\n",
        "            print(f\"Skipping prediction at index {i}: Not enough training data. Required {train_window} samples, but only {i} available.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        X_train_wfo = X_all[train_start_idx : train_end_idx]\n",
        "        y_train_wfo_returns = y_all_returns.iloc[train_start_idx : train_end_idx].values\n",
        "\n",
        "\n",
        "        lstm_model.fit(\n",
        "            X_train_wfo,\n",
        "            y_train_wfo_returns,\n",
        "            epochs=n_epochs,\n",
        "            batch_size=32,\n",
        "            verbose=0,\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "\n",
        "        predict_idx = i\n",
        "\n",
        "        if predict_idx >= len(X_all):\n",
        "            break\n",
        "\n",
        "\n",
        "        X_predict = X_all[predict_idx:predict_idx + walk_step]\n",
        "        y_actual_return = y_all_returns.iloc[predict_idx:predict_idx + walk_step].values\n",
        "        current_date = y_all_returns.index[predict_idx]\n",
        "\n",
        "\n",
        "        predicted_linear_output = lstm_model.predict(X_predict, verbose=0).flatten()\n",
        "\n",
        "\n",
        "        exp_weights = np.exp(predicted_linear_output)\n",
        "        final_weights = exp_weights / np.sum(exp_weights + K.epsilon())\n",
        "\n",
        "        asset_returns = y_actual_return[0]\n",
        "\n",
        "\n",
        "        daily_portfolio_return = np.dot(final_weights, asset_returns)\n",
        "\n",
        "\n",
        "        daily_returns.append(daily_portfolio_return)\n",
        "        daily_dates.append(current_date)\n",
        "\n",
        "        if len(daily_returns) % 50 == 0:\n",
        "             print(f\"Processing... {len(daily_returns)} days backtested (Date: {current_date.strftime('%Y-%m-%d')})\")\n",
        "\n",
        "\n",
        "\n",
        "    return pd.Series(daily_returns, index=daily_dates)\n",
        "\n",
        "\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "\n",
        "ti_datasets = get_stock_data(TICKERS, START_DATE, END_DATE)\n",
        "print(f\"Successfully loaded data for {len(ti_datasets)} out of {len(TICKERS)} tickers.\")\n",
        "\n",
        "\n",
        "for ticker in TICKERS:\n",
        "    if ticker in ti_datasets and not ti_datasets[ticker].empty:\n",
        "        ti_datasets[ticker] = create_classification_target(ti_datasets[ticker], threshold=FLAT_THRESHOLD)\n",
        "\n",
        "\n",
        "valid_tickers = [t for t in TICKERS if t in ti_datasets and not ti_datasets[t].empty and 'target' in ti_datasets[t].columns]\n",
        "X_cnn, y_cnn = create_cnn_data(ti_datasets, valid_tickers, WINDOW_SIZE)\n",
        "print(f\"\\nCNN Input Shape: {X_cnn.shape}, CNN Target Shape: {y_cnn.shape}\")\n",
        "\n",
        "\n",
        "if len(X_cnn) > 0:\n",
        "    train_size_cnn = int(len(X_cnn) * 0.8)\n",
        "    X_train_cnn, y_train_cnn = X_cnn[:train_size_cnn], y_cnn[:train_size_cnn]\n",
        "    cnn_model = build_cnn_model(X_train_cnn.shape[1:])\n",
        "\n",
        "\n",
        "    print(\"\\n--- Training CNN Model (2 Epochs for quick run) ---\")\n",
        "    cnn_model.fit(X_train_cnn, y_train_cnn, epochs=2, batch_size=32, verbose=0)\n",
        "else:\n",
        "    print(\"No CNN data generated. Skipping CNN model building and filtering.\")\n",
        "    cnn_model = None\n",
        "\n",
        "\n",
        "selected_stocks = cnn_filter_stocks(cnn_model, ti_datasets, valid_tickers, WINDOW_SIZE)\n",
        "print(f\"\\nStocks selected by CNN filter ({len(selected_stocks)}): {selected_stocks}\")\n",
        "\n",
        "\n",
        "X_lstm_full, y_lstm_returns_full, lstm_scaler = create_lstm_data(ti_datasets, selected_stocks, WINDOW_SIZE)\n",
        "\n",
        "if len(selected_stocks) > 0 and len(X_lstm_full) > 0:\n",
        "    N_SAMPLES = X_lstm_full.shape[0]\n",
        "    n_assets = len(selected_stocks)\n",
        "\n",
        "\n",
        "    TRAIN_RATIO = 0.8\n",
        "    N_INITIAL_TRAIN = int(TRAIN_RATIO * N_SAMPLES)\n",
        "    TRAIN_WINDOW_SIZE = 252\n",
        "    WALK_STEP = 1\n",
        "\n",
        "    print(f\"\\nLSTM Input Shape (X_filtered): {X_lstm_full.shape}, LSTM Target Shape (y_filtered_returns): {y_lstm_returns_full.shape}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"     WFO CONFIGURATION AND INITIAL CHECK\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total days available for LSTM: {N_SAMPLES}\")\n",
        "    print(f\"Initial Train Days (Static/CNN): {N_INITIAL_TRAIN}\")\n",
        "    print(f\"WFO Rolling Train Window Size: {TRAIN_WINDOW_SIZE} days\")\n",
        "    print(f\"WFO Backtest Period (Max Predictions): {N_SAMPLES - N_INITIAL_TRAIN}\") # Corrected calculation\n",
        "    print(\"=\"*50)\n",
        "\n",
        "\n",
        "    if N_INITIAL_TRAIN < TRAIN_WINDOW_SIZE:\n",
        "        print(f\"Warning: N_INITIAL_TRAIN ({N_INITIAL_TRAIN}) is less than TRAIN_WINDOW_SIZE ({TRAIN_WINDOW_SIZE}). Adjusting N_INITIAL_TRAIN.\")\n",
        "        N_INITIAL_TRAIN = TRAIN_WINDOW_SIZE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    portfolio_returns_wfo = walk_forward_backtest(\n",
        "        X_lstm_full,\n",
        "        y_lstm_returns_full,\n",
        "        N_INITIAL_TRAIN,\n",
        "        TRAIN_WINDOW_SIZE,\n",
        "        WALK_STEP,\n",
        "        n_epochs=2\n",
        "    )\n",
        "\n",
        "\n",
        "    if not portfolio_returns_wfo.empty:\n",
        "        ann_ret, ann_vol, sharpe, cum_ret = calculate_metrics(portfolio_returns_wfo)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"        FINAL WALK-FORWARD BACKTEST RESULTS\")\n",
        "        print(\"=\"*50)\n",
        "        print(f\"Cumulative Return:        {cum_ret * 100:.2f}%\")\n",
        "        print(f\"Annualized Return:        {ann_ret * 100:.2f}%\")\n",
        "        print(f\"Annualized Volatility:    {ann_vol * 100:.2f}%\")\n",
        "        print(f\"Sharpe Ratio (Rf=0):      {sharpe:.4f}\")\n",
        "        print(f\"Backtest Period:          {portfolio_returns_wfo.index[0].strftime('%Y-%m-%d')} to {portfolio_returns_wfo.index[-1].strftime('%Y-%m-%d')}\")\n",
        "        print(\"=\"*50)\n",
        "    else:\n",
        "        print(\"\\nNo portfolio returns generated during walk-forward backtest. Check WFO configuration or data availability.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n Not enough data or selected stocks to proceed with LSTM WFO optimization.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Ioc1Rkcpyy",
        "outputId": "5170c14c-87f0-4d7e-9af4-18f4941d5956"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4119283787.py:26: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(tickers, start=start, end=end)\n",
            "[*********************100%***********************]  87 of 87 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded data for 87 out of 87 tickers.\n",
            "\n",
            "CNN Input Shape: (88590, 30, 7, 1), CNN Target Shape: (88590, 3)\n",
            "\n",
            "--- Training CNN Model (2 Epochs for quick run) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Filtering stocks based on trained CNN prediction ('Rise' class=2) ---\n",
            "\n",
            "Stocks selected by CNN filter (85): ['ALV.DE', 'DBK.DE', 'CBK.DE', 'HAG.DE', 'DB1.DE', 'FPE.DE', 'DHER.DE', 'MUV2.DE', 'VNA.DE', 'SDF.DE', 'BNP.PA', 'ACA.PA', 'GLE.PA', 'CS.PA', 'OR.PA', 'ENGI.PA', 'SCR.PA', 'CA.PA', 'PUB.PA', 'SAN.PA', 'LLOY.L', 'BARC.L', 'HSBA.L', 'NWG.L', 'SSE.L', 'AV.L', 'PRU.L', 'LGEN.L', 'AHT.L', 'BP.L', 'SAN.MC', 'BBVA.MC', 'CABK.MC', 'AMS.MC', 'MAP.MC', 'SAB.MC', 'ELE.MC', 'ENG.MC', 'IBE.MC', 'IAG.MC', 'ISP.MI', 'UCG.MI', 'BAMI.MI', 'BMED.MI', 'FBK.MI', 'G.MI', 'AZM.MI', 'PST.MI', 'RACE.MI', 'IP.MI', 'INGA.AS', 'ADYEN.AS', 'ABN.AS', 'WKL.AS', 'AD.AS', 'ASML.AS', 'HEIA.AS', 'TKWY.AS', 'KPN.AS', 'NDA-SE.ST', 'SEB-A.ST', 'SHB-A.ST', 'SWED-A.ST', 'GETI-B.ST', 'VOLV-B.ST', 'AZN.ST', 'TELIA.ST', 'ESSITY-B.ST', 'ERIC-B.ST', 'UBSG.SW', 'VETN.SW', 'ZURN.SW', 'SGSN.SW', 'GIVN.SW', 'SREN.SW', 'NOVN.SW', 'KBC.BR', 'ABI.BR', 'UCB.BR', 'ACKB.BR', 'SOLB.BR', 'TUB.BR', 'ELI.BR', 'WDP.BR', 'COLR.BR']\n",
            "\n",
            "LSTM Input Shape (X_filtered): (623, 30, 595), LSTM Target Shape (y_filtered_returns): (623, 85)\n",
            "\n",
            "==================================================\n",
            "     WFO CONFIGURATION AND INITIAL CHECK\n",
            "==================================================\n",
            "Total days available for LSTM: 623\n",
            "Initial Train Days (Static/CNN): 498\n",
            "WFO Rolling Train Window Size: 252 days\n",
            "WFO Backtest Period (Max Predictions): 125\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Walk-Forward Loop...\n",
            "Processing... 50 days backtested (Date: 2024-12-18)\n",
            "Processing... 100 days backtested (Date: 2025-04-28)\n",
            "\n",
            "==================================================\n",
            "        FINAL WALK-FORWARD BACKTEST RESULTS\n",
            "==================================================\n",
            "Cumulative Return:        8.40%\n",
            "Annualized Return:        17.65%\n",
            "Annualized Volatility:    19.47%\n",
            "Sharpe Ratio (Rf=0):      0.9063\n",
            "Backtest Period:          2024-10-10 to 2025-09-26\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}